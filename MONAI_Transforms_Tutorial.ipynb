{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84a0790",
      "metadata": {
        "id": "c84a0790"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import monai\n",
        "import torch\n",
        "import time\n",
        "\n",
        "print('monai\\'s version:', monai.__version__)\n",
        "print('torch\\'s version:', torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0e5b56",
      "metadata": {
        "id": "0e0e5b56"
      },
      "outputs": [],
      "source": [
        "keys = ['img', 'seg']\n",
        "data_dir = './data/'\n",
        "fns = os.listdir(data_dir+'img/')\n",
        "data = [{key: data_dir+key+'/'+fn for key in keys} for fn in fns]\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74c2aeb9",
      "metadata": {
        "id": "74c2aeb9"
      },
      "source": [
        "![image.png](attachment:3110df9a-e7c8-4e97-b2c4-cce523030425.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6c44a2",
      "metadata": {
        "id": "be6c44a2"
      },
      "source": [
        "## Transforms\n",
        "- Data I/O\n",
        "- Pre-processing\n",
        "- Augmentation\n",
        "- Post-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f2eddf",
      "metadata": {
        "id": "c3f2eddf"
      },
      "outputs": [],
      "source": [
        "spatial_size = [128, 128, 16]\n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  # Data I/O\n",
        "                                  monai.transforms.AddChanneld(keys),  # Pre-processing\n",
        "                                  monai.transforms.EnsureTyped(keys),  # Pre-processing\n",
        "                                  monai.transforms.NormalizeIntensityd(keys='img'),  # Pre-processing\n",
        "                                  monai.transforms.Resized(keys, spatial_size=spatial_size, mode=['area', 'nearest']),  # Augmentation\n",
        "                                  monai.transforms.RandScaleIntensityd(keys, 0.2, prob=0.5),  # Augmentation\n",
        "                                  monai.transforms.RandFlipd(keys, prob=0.5)])  # Augmentation\n",
        "\n",
        "trans_original = monai.transforms.Compose([monai.transforms.LoadImaged(keys)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c481768",
      "metadata": {
        "id": "2c481768"
      },
      "outputs": [],
      "source": [
        "def plot_trans_imgs(trans1, trans2, data):\n",
        "    img1 = trans1(data)['img']\n",
        "    if len(img1.shape)==4:\n",
        "        img1 = img1[0]\n",
        "    idx1 = img1.shape[-1]//2\n",
        "    img2 = trans2(data)['img']\n",
        "    if len(img2.shape)==4:\n",
        "        img2 = img2[0]\n",
        "    idx2 = img2.shape[-1]//2\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(img1[..., idx1], cmap='gray')\n",
        "    plt.title('Img 1')\n",
        "    plt.xlabel(str(img1.shape)+', '+str(idx1))\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(img2[..., idx2], cmap='gray')\n",
        "    plt.title('Img 2')\n",
        "    plt.xlabel(str(img2.shape)+', '+str(idx2))\n",
        "    plt.show()\n",
        "    \n",
        "def plot_trans_imgs_hist(trans1, trans2, data):\n",
        "    img1 = trans1(data)['img']\n",
        "    if len(img1.shape)==4:\n",
        "        img1 = img1[0]\n",
        "    idx1 = img1.shape[-1]//2\n",
        "    img2 = trans2(data)['img']\n",
        "    if len(img2.shape)==4:\n",
        "        img2 = img2[0]\n",
        "    idx2 = img2.shape[-1]//2\n",
        "    \n",
        "    h = [img1.reshape([-1]), img2.reshape([-1])]\n",
        "    for i in range(2):\n",
        "        if type(h[i]) == torch.Tensor:\n",
        "            h[i] = h[i].numpy()\n",
        "    \n",
        "    plt.figure(figsize=(16, 12))\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(img1[..., idx1], cmap='gray')\n",
        "    plt.title('Img 1')\n",
        "    plt.xlabel(str(img1.shape)+', '+str(idx1))\n",
        "    plt.subplot(222)\n",
        "    plt.hist(h[0], bins=30, rwidth=.8)\n",
        "    plt.title('Img 1')\n",
        "    plt.xlabel('Mean:'+str(round(h[0].mean(), 4))+', StD:'+str(round(h[0].std(), 4)))\n",
        "    \n",
        "    plt.subplot(223)\n",
        "    plt.imshow(img2[..., idx2], cmap='gray')\n",
        "    plt.title('Img 2')\n",
        "    plt.xlabel(str(img2.shape)+', '+str(idx2))\n",
        "    plt.subplot(224)\n",
        "    plt.hist(h[1], bins=30, rwidth=.8)\n",
        "    plt.title('Img 2')\n",
        "    plt.xlabel('Mean:'+str(round(h[1].mean(), 4))+', StD:'+str(round(h[1].std(), 4)))\n",
        "    \n",
        "    plt.show()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b7affbe",
      "metadata": {
        "id": "1b7affbe"
      },
      "outputs": [],
      "source": [
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c649d91",
      "metadata": {
        "id": "4c649d91"
      },
      "source": [
        "#### Customize transforms: Lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48d0aa2",
      "metadata": {
        "id": "d48d0aa2"
      },
      "outputs": [],
      "source": [
        "def sqr(img):\n",
        "    return img**2\n",
        "\n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys, image_only=True), \n",
        "                                  monai.transforms.AddChanneld(keys), \n",
        "                                  monai.transforms.Lambdad(keys, sqr)])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb4f8fe",
      "metadata": {
        "id": "2eb4f8fe"
      },
      "source": [
        "#### Customize transforms: inherit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "191aef47",
      "metadata": {
        "id": "191aef47"
      },
      "outputs": [],
      "source": [
        "class Sqrd(monai.transforms.MapTransform):\n",
        "    def __init__(self, params=None):\n",
        "        self.params = params\n",
        "        \n",
        "    def __call__(self, inputs):\n",
        "        inputs['img'] = inputs['img']**2\n",
        "        return inputs\n",
        "\n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys, image_only=True), \n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  Sqrd(keys)])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93ce3fc",
      "metadata": {
        "id": "b93ce3fc"
      },
      "source": [
        "#### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d0e4c9",
      "metadata": {
        "id": "c2d0e4c9"
      },
      "outputs": [],
      "source": [
        "# Fix the saveOriginalShaped transform\n",
        "\n",
        "class SaveOriginalShaped(monai.transforms.MapTransform):\n",
        "    def __init__(self, img_key, shape_key='ori_shape'):\n",
        "        self.img_key = img_key\n",
        "        self.shape_key = shape_key\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        inputs[self.shape_key] = inputs[self.img_key].shape\n",
        "        return inputs\n",
        "    \n",
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys), \n",
        "                                  monai.transforms.AddChanneld(keys), \n",
        "                                  SaveOriginalShaped('img', 'ori_shape'),\n",
        "                                  monai.transforms.Resized(keys, spatial_size=(100, 100, 100),),\n",
        "                                  monai.transforms.ToTensord(keys)])\n",
        "\n",
        "img_seg = trans(data[0])\n",
        "print('New shape:', img_seg['img'].shape)\n",
        "print('Original Shape:', img_seg['ori_shape'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e7c676",
      "metadata": {
        "id": "57e7c676"
      },
      "source": [
        "### ***Data I/O***\n",
        "---\n",
        "- monai.transforms.LoadImaged\n",
        "- monai.transforms.SaveImaged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b19e3142",
      "metadata": {
        "id": "b19e3142"
      },
      "outputs": [],
      "source": [
        "trans_io = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                     monai.transforms.SaveImaged(keys='img',\n",
        "                                                                 output_dir='./',\n",
        "                                                                 output_postfix='test1',\n",
        "                                                                 output_ext='.nii.gz',\n",
        "                                                                 separate_folder=False)])\n",
        "\n",
        "_ = trans_io(data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82a38ad5",
      "metadata": {
        "id": "82a38ad5"
      },
      "source": [
        "### ***Pre-processing***\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b2809e0",
      "metadata": {
        "id": "7b2809e0"
      },
      "source": [
        "#### Utility\n",
        "- monai.transforms.AddChanneld\n",
        "- monai.transforms.EnsureTyped\n",
        "- monai.transforms.ToTensord"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e2ea03e",
      "metadata": {
        "id": "0e2ea03e"
      },
      "source": [
        "##### **monai.transforms.AddChanneld**\n",
        "For Conv's matrix computation (channel-first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8ae59e",
      "metadata": {
        "id": "4e8ae59e"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  \n",
        "                                  monai.transforms.AddChanneld(keys),]) \n",
        "\n",
        "trans_original(data[0])['img'].shape, trans(data[0])['img'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4186ecb6",
      "metadata": {
        "id": "4186ecb6"
      },
      "source": [
        "##### **monai.transforms.EnsureTyped**\n",
        "Ensure the input data to be a PyTorch Tensor or numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "144aae77",
      "metadata": {
        "id": "144aae77"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  \n",
        "                                  monai.transforms.EnsureTyped(keys, data_type='numpy', dtype=np.float32,),]) \n",
        "\n",
        "trans2 = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  \n",
        "                                   monai.transforms.EnsureTyped(keys)]) \n",
        "\n",
        "type(trans_original(data[0])['img']), type(trans(data[0])['img']), type(trans2(data[0])['img'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94fd1fcd",
      "metadata": {
        "id": "94fd1fcd"
      },
      "source": [
        "##### **monai.transforms.ToTensord**\n",
        "Convert the input to a torch tensor. Can also choose target device to put the converted data, such as 'cuda' => put the data into GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d59f80",
      "metadata": {
        "id": "c0d59f80"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  \n",
        "                                  monai.transforms.ToTensord(keys, dtype=torch.float32, device='cuda')]) \n",
        "\n",
        "type(trans_original(data[0])['img']), type(trans(data[0])['img']), trans(data[0])['img'].device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5c540f0",
      "metadata": {
        "id": "b5c540f0"
      },
      "source": [
        "#### Intensity\n",
        "- monai.transforms.NormalizeIntensityd\n",
        "- monai.transforms.ScaleIntensityRanged\n",
        "- monai.transforms.GaussianSmoothd\n",
        "- monai.transforms.HistogramNormalized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46303d83",
      "metadata": {
        "id": "46303d83"
      },
      "source": [
        "##### **monai.transforms.NormalizeIntensityd**\n",
        "Normalize input using calculated mean and std by default. You can provide the subtrahend and divisor instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8f6c81",
      "metadata": {
        "id": "5d8f6c81"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  \n",
        "                                  monai.transforms.NormalizeIntensityd(keys, )])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b16afd29",
      "metadata": {
        "id": "b16afd29"
      },
      "source": [
        "##### **monai.transforms.ScaleIntensityRanged**\n",
        "Apply specific intensity scaling to the whole numpy array. Scaling from [a_min, a_max] to [b_min, b_max] with clip option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e4395a6",
      "metadata": {
        "id": "2e4395a6"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  \n",
        "                                  monai.transforms.ScaleIntensityRanged(keys='img', clip=True,\n",
        "                                                                        a_min=-57, a_max=164,\n",
        "                                                                        b_min=0.0, b_max=1.0),])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3524b493",
      "metadata": {
        "id": "3524b493"
      },
      "source": [
        "##### **monai.transforms.GaussianSmoothd**\n",
        "Apply Gaussian smooth to the input data based on specified sigma parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "098ed57d",
      "metadata": {
        "id": "098ed57d"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  \n",
        "                                  monai.transforms.GaussianSmoothd(keys, sigma=1.)])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672c0d5c",
      "metadata": {
        "id": "672c0d5c"
      },
      "source": [
        "##### **monai.transforms.HistogramNormalized**\n",
        "Apply the histogram normalization to input image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf71dd2",
      "metadata": {
        "id": "4cf71dd2"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),  \n",
        "                                  monai.transforms.HistogramNormalized(keys, min=0, max=1)])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c42dca1",
      "metadata": {
        "id": "1c42dca1"
      },
      "source": [
        "#### Spatial\n",
        "- monai.transforms.SpatialPadd\n",
        "- monai.transforms.SpatialCropd\n",
        "- monai.transforms.CropForegroundd\n",
        "- monai.transforms.Spacingd\n",
        "- monai.transforms.Resized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "148780a8",
      "metadata": {
        "id": "148780a8"
      },
      "source": [
        "##### **monai.transforms.SpatialPadd**\n",
        "Performs padding to the data, symmetric for all sides or all on one side for each dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33559847",
      "metadata": {
        "id": "33559847"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.SpatialPadd(keys, spatial_size=(600, 600, 60), method='symmetric')])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c47ed12",
      "metadata": {
        "id": "6c47ed12"
      },
      "outputs": [],
      "source": [
        "trans2 = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.SpatialPadd(keys, spatial_size=(600, 600, 60), method='end')])\n",
        "\n",
        "plot_trans_imgs(trans, trans2, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5477f44",
      "metadata": {
        "id": "c5477f44"
      },
      "source": [
        "##### **monai.transforms.SpatialCropd**\n",
        "General purpose cropper to produce sub-volume region of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca303f5",
      "metadata": {
        "id": "6ca303f5"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.SpatialCropd(keys, roi_center=(256, 256, 20), roi_size=(256, 256, 16))])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8970f6f2",
      "metadata": {
        "id": "8970f6f2"
      },
      "source": [
        "##### **monai.transforms.CropForegroundd**\n",
        "Crop only the foreground object of the expected images. The typical usage is to help training and evaluation if the valid part is small in the whole medical image. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed0aa2b",
      "metadata": {
        "id": "6ed0aa2b"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.CropForegroundd(keys, source_key='img')])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "574def8e",
      "metadata": {
        "id": "574def8e"
      },
      "source": [
        "##### **monai.transforms.Spacingd**\n",
        "Resample input image into the specified resolution pixdim (mm). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a9969b",
      "metadata": {
        "id": "32a9969b"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.Spacingd(keys, pixdim=(2, 2, 2))])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e816a920",
      "metadata": {
        "id": "e816a920"
      },
      "source": [
        "##### **monai.transforms.Resized**\n",
        "Resize the input image to given spatial size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68656c26",
      "metadata": {
        "id": "68656c26"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.Resized(keys, spatial_size=(128, 128, 16))])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3970ff90",
      "metadata": {
        "id": "3970ff90"
      },
      "source": [
        "### ***Augmentation***\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "350f2bb1",
      "metadata": {
        "id": "350f2bb1"
      },
      "source": [
        "#### Intensity\n",
        "- monai.transforms.RandGaussianNoised\n",
        "- monai.transforms.RandStdShiftIntensityd\n",
        "- monai.transforms.RandAdjustContrastd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0ae6d3f",
      "metadata": {
        "id": "f0ae6d3f"
      },
      "source": [
        "##### **monai.transforms.RandGaussianNoised**\n",
        "Add Gaussian noise to image with specified mean and std."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb462003",
      "metadata": {
        "id": "fb462003"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.RandGaussianNoised(keys, prob=0.5, mean=0.0, std=200)])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40498055",
      "metadata": {
        "id": "40498055"
      },
      "source": [
        "##### **monai.transforms.RandStdShiftIntensityd**\n",
        "Randomly scale the intensity of input image by *v = v * (1 + factor)* where the factor is randomly picked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e35ebd",
      "metadata": {
        "id": "f7e35ebd"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.RandStdShiftIntensityd(keys, prob=0.5, factors=0.5, nonzero=False, channel_wise=True, )])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bedd7ad7",
      "metadata": {
        "id": "bedd7ad7"
      },
      "source": [
        "##### **monai.transforms.RandAdjustContrastd**\n",
        "Randomly changes image intensity by gamma. Each pixel/voxel intensity is updated as:\n",
        "```\n",
        "x = ((x - min) / intensity_range) ^ gamma * intensity_range + min\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee241074",
      "metadata": {
        "id": "ee241074"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.RandAdjustContrastd(keys, prob=0.5, gamma=(0.5, 4.5))])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f0a322",
      "metadata": {
        "id": "98f0a322"
      },
      "source": [
        "#### Spatial\n",
        "- monai.transforms.RandSpatialCropd\n",
        "- monai.transforms.RandRotated\n",
        "- monai.transforms.RandRotate90d\n",
        "- monai.transforms.RandFlipd\n",
        "- monai.transforms.RandGridDistortiond"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3554329",
      "metadata": {
        "id": "c3554329"
      },
      "source": [
        "##### **monai.transforms.RandSpatialCropd**\n",
        "Crop image with random size or specific size ROI. It can crop at a random position as center or at the image center."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2f2972",
      "metadata": {
        "id": "eb2f2972"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.RandSpatialCropd(keys,\n",
        "                                                                    roi_size=(256, 256, 16),\n",
        "                                                                    random_center=True,\n",
        "                                                                    random_size=False)])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d72bce",
      "metadata": {
        "id": "98d72bce"
      },
      "source": [
        "##### **monai.transforms.RandRotated**\n",
        "Randomly rotate the input arrays for each axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a632fbdc",
      "metadata": {
        "id": "a632fbdc"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.RandRotated(keys, prob=1., range_z=1., keep_size=True, )])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80df7151",
      "metadata": {
        "id": "80df7151"
      },
      "source": [
        "##### **monai.transforms.RandRotate90d**\n",
        "Input arrays are rotated by 90 degrees in the plane specified by spatial_axes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7d1cc3",
      "metadata": {
        "id": "fc7d1cc3"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.RandRotate90d(keys, prob=0.5, spatial_axes=(0, 1))])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "693eec51",
      "metadata": {
        "id": "693eec51"
      },
      "source": [
        "##### **monai.transforms.RandFlip**\n",
        "Randomly flips the image along axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "160acd86",
      "metadata": {
        "id": "160acd86"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.RandFlipd(keys, prob=0.5, spatial_axis=(0, 1))])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4a15497",
      "metadata": {
        "id": "d4a15497"
      },
      "source": [
        "##### monai.transforms.RandGridDistortiond\n",
        "Random grid distortion, refer to: https://github.com/albumentations-team/albumentations/blob/master/albumentations/augmentations/transforms.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2956efe6",
      "metadata": {
        "id": "2956efe6"
      },
      "outputs": [],
      "source": [
        "trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys),\n",
        "                                  monai.transforms.AddChanneld(keys),\n",
        "                                  monai.transforms.RandGridDistortiond(keys, prob=0.5, distort_limit=0.2)])\n",
        "\n",
        "plot_trans_imgs_hist(trans_original, trans, data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f0c6b31",
      "metadata": {
        "id": "8f0c6b31"
      },
      "source": [
        "### ***Post-processing***\n",
        "---\n",
        "- monai.transforms.Activationsd\n",
        "- monai.transforms.AsDiscreted\n",
        "- monai.transforms.KeepLargestConnectedComponentd\n",
        "- monai.transforms.Invertd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d77283d3",
      "metadata": {
        "id": "d77283d3"
      },
      "source": [
        "*Prepare a pre-transform func and a model for post-processing, then do inference*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2092190",
      "metadata": {
        "id": "c2092190"
      },
      "outputs": [],
      "source": [
        "from monai.apps.mmars import RemoteMMARKeys\n",
        "from monai.apps import load_from_mmar\n",
        "\n",
        "pre_trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys='img'),  \n",
        "                                      monai.transforms.AddChanneld(keys='img'), \n",
        "                                      monai.transforms.Spacingd(keys='img', pixdim=[1.5, 1.5, 2.0], mode='bilinear'),\n",
        "                                      monai.transforms.ScaleIntensityRanged(keys='img', clip=True,\n",
        "                                                                            a_min=-57, a_max=164,\n",
        "                                                                            b_min=0.0, b_max=1.0),\n",
        "                                      monai.transforms.CropForegroundd(keys='img', source_key='img'),\n",
        "                                      monai.transforms.SpatialCropd(keys='img', roi_center=(100, 100, 49), roi_size=(128, 128, 64)),\n",
        "                                      monai.transforms.ToTensord(keys='img', device='cuda:0')]) \n",
        "\n",
        "def get_mmar_pretrained(mmar_dir='./model/'):\n",
        "    '''\n",
        "    Get pre-trained spleen segmentation model from NGC\n",
        "    mmar_dir: Download the target MMAR to this directory\n",
        "    '''\n",
        "    mmar = {\n",
        "        RemoteMMARKeys.ID: \"clara_pt_spleen_ct_segmentation_1\",\n",
        "        RemoteMMARKeys.NAME: \"clara_pt_spleen_ct_segmentation\",\n",
        "        RemoteMMARKeys.FILE_TYPE: \"zip\",\n",
        "        RemoteMMARKeys.HASH_TYPE: \"md5\",\n",
        "        RemoteMMARKeys.HASH_VAL: None,\n",
        "        RemoteMMARKeys.MODEL_FILE: os.path.join(\"models\", \"model.pt\"),\n",
        "        RemoteMMARKeys.CONFIG_FILE: os.path.join(\"config\", \"config_train.json\"),\n",
        "        RemoteMMARKeys.VERSION: 1,\n",
        "    }\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = load_from_mmar(\n",
        "                item=mmar[RemoteMMARKeys.NAME],\n",
        "                mmar_dir=mmar_dir,\n",
        "                map_location=device,\n",
        "                pretrained=True)\n",
        "    return model.to(device)\n",
        "\n",
        "model = get_mmar_pretrained(mmar_dir='./model/')\n",
        "\n",
        "d = pre_trans(data[0])\n",
        "d['pred'] = model(d['img'][None, ...])[0]\n",
        "d['pred'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f65a0ed6",
      "metadata": {
        "id": "f65a0ed6"
      },
      "outputs": [],
      "source": [
        "def plot_trans_pred_hist(trans1, trans2, data):\n",
        "    img1 = trans1(data)['pred']\n",
        "    print('Img 1 original shape:', img1.shape)\n",
        "    if len(img1.shape)==4:\n",
        "        img1 = img1[img1.shape[0]-1]\n",
        "    idx1 = img1.shape[-1]//2\n",
        "    img2 = trans2(data)['pred']\n",
        "    print('Img 2 original shape:', img2.shape)\n",
        "    if len(img2.shape)==4:\n",
        "        img2 = img2[img2.shape[0]-1]\n",
        "    idx2 = img2.shape[-1]//2\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(img1[..., idx1], cmap='gray')\n",
        "    plt.title('Img 1')\n",
        "    plt.xlabel(str(img1.shape)+', '+str(idx1))\n",
        "    plt.subplot(222)\n",
        "    plt.hist(img1.reshape([-1]), bins=30, rwidth=.8)\n",
        "    plt.title('Img 1')\n",
        "    plt.xlabel('Mean:'+str(round(img1.mean(), 4))+', StD:'+str(round(img1.std(), 4)))\n",
        "    \n",
        "    plt.subplot(223)\n",
        "    plt.imshow(img2[..., idx2], cmap='gray')\n",
        "    plt.title('Img 2')\n",
        "    plt.xlabel(str(img2.shape)+', '+str(idx2))\n",
        "    plt.subplot(224)\n",
        "    plt.hist(img2.reshape([-1]), bins=30, rwidth=.8)\n",
        "    plt.title('Img 2')\n",
        "    plt.xlabel('Mean:'+str(round(img2.mean(), 4))+', StD:'+str(round(img2.std(), 4)))\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e0c96b",
      "metadata": {
        "id": "05e0c96b"
      },
      "source": [
        "##### **monai.transforms.Activationsd**\n",
        "Add activation operations to the model output, typically Sigmoid or Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a7440b",
      "metadata": {
        "id": "68a7440b"
      },
      "outputs": [],
      "source": [
        "original_post_trans = monai.transforms.Compose([monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "post_trans = monai.transforms.Compose([monai.transforms.Activationsd(keys='pred', softmax=True),\n",
        "                                       monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "plot_trans_pred_hist(original_post_trans, post_trans, d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9bc30b9",
      "metadata": {
        "id": "a9bc30b9"
      },
      "source": [
        "##### **monai.transforms.AsDiscreted**\n",
        "Execute after model forward to transform model output to discrete values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea674fd9",
      "metadata": {
        "id": "ea674fd9"
      },
      "outputs": [],
      "source": [
        "original_post_trans = monai.transforms.Compose([monai.transforms.Activationsd(keys='pred', softmax=True),\n",
        "                                                monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "post_trans = monai.transforms.Compose([monai.transforms.Activationsd(keys='pred', softmax=True),\n",
        "                                       monai.transforms.AsDiscreted(keys='pred', argmax=True),\n",
        "                                       monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "plot_trans_pred_hist(original_post_trans, post_trans, d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98c5c73",
      "metadata": {
        "id": "a98c5c73"
      },
      "source": [
        "##### monai.transforms.KeepLargestConnectedComponentd\n",
        "Keeps only the largest connected component in the image. This transform can be used as a post-processing step to clean up over-segment areas in model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab1f694",
      "metadata": {
        "id": "dab1f694"
      },
      "outputs": [],
      "source": [
        "# add fake preds\n",
        "d['pred'][1, ..., 30:35][80:100, 80:100] = 10\n",
        "\n",
        "original_post_trans = monai.transforms.Compose([monai.transforms.Activationsd(keys='pred', softmax=True),\n",
        "                                                monai.transforms.AsDiscreted(keys='pred', argmax=True),\n",
        "                                                monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "post_trans = monai.transforms.Compose([monai.transforms.Activationsd(keys='pred', softmax=True),\n",
        "                                       monai.transforms.AsDiscreted(keys='pred', argmax=True),\n",
        "                                       monai.transforms.KeepLargestConnectedComponentd(keys='pred', applied_labels=1),\n",
        "                                       monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "plot_trans_pred_hist(original_post_trans, post_trans, d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318a4ae2",
      "metadata": {
        "id": "318a4ae2"
      },
      "source": [
        "##### **monai.transforms.Invertd**\n",
        "Automatically invert the previously applied transforms. A typical usage is to apply the inverse of the preprocessing on input *image* to the model *pred*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f7a37b",
      "metadata": {
        "id": "02f7a37b"
      },
      "outputs": [],
      "source": [
        "original_post_trans = monai.transforms.Compose([monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "post_trans = monai.transforms.Compose([monai.transforms.Invertd(keys='pred',\n",
        "                                                                transform=pre_trans,\n",
        "                                                                orig_keys='img',\n",
        "                                                                meta_keys='pred_meta_dict',\n",
        "                                                                nearest_interp=True,\n",
        "                                                                to_tensor=True,\n",
        "                                                                device='cuda'),\n",
        "                                       monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "plot_trans_pred_hist(original_post_trans, post_trans, d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bfb152e",
      "metadata": {
        "id": "9bfb152e"
      },
      "outputs": [],
      "source": [
        "original_post_trans = monai.transforms.Compose([monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "post_trans = monai.transforms.Compose([monai.transforms.Activationsd(keys='pred', softmax=True),\n",
        "                                       monai.transforms.AsDiscreted(keys='pred', argmax=True),\n",
        "                                       monai.transforms.KeepLargestConnectedComponentd(keys='pred', applied_labels=1),\n",
        "                                       monai.transforms.Invertd(keys='pred',\n",
        "                                                                transform=pre_trans,\n",
        "                                                                orig_keys='img',\n",
        "                                                                meta_keys='pred_meta_dict',\n",
        "                                                                nearest_interp=True,\n",
        "                                                                to_tensor=True,\n",
        "                                                                device='cuda'),\n",
        "                                       monai.transforms.EnsureTyped(keys='pred', data_type='numpy')])\n",
        "\n",
        "plot_trans_pred_hist(original_post_trans, post_trans, d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56feab5c",
      "metadata": {
        "id": "56feab5c"
      },
      "source": [
        "## End-to-end Exercise\n",
        "Load => Pre-processing => Inference => Post-processing => Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f64879",
      "metadata": {
        "id": "e7f64879"
      },
      "outputs": [],
      "source": [
        "# Fix pre_trans:\n",
        "# - Spacing: [1.5, 1.5, 2.0]\n",
        "# - Scale intensity range: from [-57, 164] to [0, 1]\n",
        "\n",
        "pre_trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys='img'),  \n",
        "                                      monai.transforms.AddChanneld(keys='img'), \n",
        "                                      monai.transforms.Spacingd(keys='img', pixdim=[1.5, 1.5, 2.0], mode='bilinear'),\n",
        "                                      monai.transforms.ScaleIntensityRanged(keys='img', clip=True,\n",
        "                                                                            a_min=-57, a_max=164,\n",
        "                                                                            b_min=0.0, b_max=1.0),\n",
        "                                      monai.transforms.CropForegroundd(keys='img', source_key='img'),\n",
        "                                      monai.transforms.ToTensord(keys='img', device='cuda:0')]) \n",
        "\n",
        "\n",
        "# Fix post_trans:\n",
        "# - Activation: Softmax\n",
        "# - Keep largest connected component: applied_labels=1\n",
        "\n",
        "post_trans = monai.transforms.Compose([monai.transforms.Activationsd(keys='pred', softmax=True),\n",
        "                                       monai.transforms.Invertd(keys='pred',\n",
        "                                                                transform=pre_trans,\n",
        "                                                                orig_keys='img',\n",
        "                                                                meta_keys='pred_meta_dict',\n",
        "                                                                nearest_interp=False,\n",
        "                                                                to_tensor=True,\n",
        "                                                                device='cuda'),\n",
        "                                       monai.transforms.AsDiscreted(keys='pred', argmax=True),\n",
        "                                       monai.transforms.KeepLargestConnectedComponentd(keys='pred', applied_labels=1),\n",
        "                                       monai.transforms.SaveImaged(keys='pred',\n",
        "                                                                   output_dir='./',\n",
        "                                                                   output_postfix='pred',\n",
        "                                                                   output_ext='.nii.gz',\n",
        "                                                                   meta_keys= \"pred_meta_dict\",\n",
        "                                                                   resample=False,\n",
        "                                                                   squeeze_end_dims=True,\n",
        "                                                                   separate_folder=False)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a09c36fc",
      "metadata": {
        "id": "a09c36fc"
      },
      "source": [
        "#### Process\n",
        "***Load => Pre-processing*** => Inference => Post-processing => Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59817b9",
      "metadata": {
        "id": "a59817b9"
      },
      "outputs": [],
      "source": [
        "d = pre_trans(data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83994e8d",
      "metadata": {
        "id": "83994e8d"
      },
      "source": [
        "Load => Pre-processing => ***Inference*** => Post-processing => Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f07321d",
      "metadata": {
        "id": "6f07321d"
      },
      "outputs": [],
      "source": [
        "pred = monai.inferers.sliding_window_inference(d['img'][None, ...], sw_batch_size=4, roi_size=(160, 160, 160), overlap=0.5, predictor=model)\n",
        "d['pred'] = pred[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39ec9603",
      "metadata": {
        "id": "39ec9603"
      },
      "source": [
        "Load => Pre-processing => Inference => ***Post-processing => Save***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b141a0f5",
      "metadata": {
        "id": "b141a0f5"
      },
      "outputs": [],
      "source": [
        "_ = post_trans(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5966a3e",
      "metadata": {
        "id": "a5966a3e"
      },
      "source": [
        "![image.png](attachment:154d40b5-60aa-4880-b019-a5ac5ba300c3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd906c24",
      "metadata": {
        "id": "cd906c24"
      },
      "source": [
        "## GPU Accelerated Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9ab443",
      "metadata": {
        "id": "7c9ab443"
      },
      "outputs": [],
      "source": [
        "# Without GPU Accelerated\n",
        "\n",
        "pre_trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys='img'),  \n",
        "                                      monai.transforms.AddChanneld(keys='img'), \n",
        "                                      monai.transforms.Spacingd(keys='img', pixdim=[1.5, 1.5, 2.0], mode='bilinear'),\n",
        "                                      monai.transforms.ScaleIntensityRanged(keys='img', clip=True,\n",
        "                                                                            a_min=-57, a_max=164,\n",
        "                                                                            b_min=0.0, b_max=1.0),\n",
        "                                      monai.transforms.CropForegroundd(keys='img', source_key='img'),\n",
        "                                      monai.transforms.RandSpatialCropd(keys='img', roi_size=(192, 192, 64)),\n",
        "                                      monai.transforms.Resized(keys='img', spatial_size=[100, 100, 100]),\n",
        "                                      monai.transforms.RandFlipd(keys='img', prob=1),\n",
        "                                      monai.transforms.RandGaussianNoised(keys='img', prob=1, std=0.5),\n",
        "                                      monai.transforms.ToTensord(keys='img')]) \n",
        "\n",
        "n = 20\n",
        "t1 = time.time()\n",
        "for i in range(n):\n",
        "    img = pre_trans(data[0])\n",
        "t2 = time.time()\n",
        "print(round((t2-t1)/n, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfa0c6b",
      "metadata": {
        "id": "1cfa0c6b"
      },
      "outputs": [],
      "source": [
        "# With GPU Accelerated\n",
        "\n",
        "pre_trans = monai.transforms.Compose([monai.transforms.LoadImaged(keys='img'),  \n",
        "                                      monai.transforms.AddChanneld(keys='img'),\n",
        "                                      monai.transforms.ToTensord(keys='img', device='cuda'),\n",
        "                                      monai.transforms.Spacingd(keys='img', pixdim=[1.5, 1.5, 2.0], mode='bilinear'),\n",
        "                                      monai.transforms.ScaleIntensityRanged(keys='img', clip=True,\n",
        "                                                                            a_min=-57, a_max=164,\n",
        "                                                                            b_min=0.0, b_max=1.0),\n",
        "                                      monai.transforms.CropForegroundd(keys='img', source_key='img'),\n",
        "                                      monai.transforms.RandSpatialCropd(keys='img', roi_size=(192, 192, 64)),\n",
        "                                      monai.transforms.Resized(keys='img', spatial_size=[100, 100, 100]),\n",
        "                                      monai.transforms.RandFlipd(keys='img', prob=1),\n",
        "                                      monai.transforms.RandGaussianNoised(keys='img', prob=1, std=0.5)]) \n",
        "\n",
        "n = 20\n",
        "t1 = time.time()\n",
        "for i in range(n):\n",
        "    img = pre_trans(data[0])\n",
        "t2 = time.time()\n",
        "print(round((t2-t1)/n, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edfec82e",
      "metadata": {
        "id": "edfec82e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}